{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coffee price prediction\n",
    "The objective is to predict the rating of coffee beans based on their origin, flavour and tasting notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define some utilities related to plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "\n",
    "def _hist(s: pd.Series, bins=None) -> pd.Series:\n",
    "    if is_numeric_dtype(s.dtype):\n",
    "        if bins is not None:\n",
    "            count, division = np.histogram(s, bins, density=True)\n",
    "        else:\n",
    "            count, division = np.histogram(s, density=True)\n",
    "        index = (division[:-1] + division[1:]) / 2\n",
    "        return pd.Series(index=index, data=count, name=s.name), division\n",
    "    else:\n",
    "        h = s.value_counts() / len(s)\n",
    "        if bins is not None:\n",
    "            h = h[bins]\n",
    "        return h, h.index\n",
    "\n",
    "\n",
    "def plot_hist(df: pd.DataFrame, col, by=None, bins=None) -> go.Figure:\n",
    "    hist_all, bins = _hist(df[col], bins)\n",
    "    if by:\n",
    "        data = pd.DataFrame({name: _hist(group[col], bins=bins)[0] for name, group in df.groupby(by)})\n",
    "    else:\n",
    "        data = hist_all.to_frame(\"all\")\n",
    "    fig = data.multiply(100).plot.bar(\n",
    "        barmode=\"group\", labels={\"value\": \"percentage\", \"index\": col} | ({\"variable\": by} if by else {})\n",
    "    )\n",
    "    if by is None:\n",
    "        fig.update_layout(showlegend=False)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def write_fig_to_html(fig, filename: str) -> None:\n",
    "    with open(f\"charts/{filename}\", \"w\") as f:\n",
    "        f.write(fig.to_html(full_html=False, include_plotlyjs='cdn'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/simplified_coffee.csv\")\n",
    "for col in [\"name\", \"roaster\", \"roast\", \"loc_country\", \"origin\", \"review\"]:\n",
    "    df[col] = df[col].astype(\"string\")\n",
    "\n",
    "df[\"review_date\"] = pd.to_datetime(df[\"review_date\"])\n",
    "df = df.rename(columns={\"loc_country\": \"roaster_country\", \"100g_USD\": \"price_per_100g\", \"origin\": \"country_of_origin\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first check for NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only column with NaNs is the roast. Since there are only 12 missing values, we could just remove these rows. However, since most coffees have the same roast type (as will see later), let us fill with the modal value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"roast\"] = df[\"roast\"].fillna(df[\"roast\"].mode().iloc[0])\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fix a typo in the roaster country for one coffee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"roaster_country\"] = df[\"roaster_country\"].str.replace(\"New Taiwan\", \"Taiwan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's replace some strange characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace = {\"’s\": \"'s\", \"é\": \"e\", \"’\": \"'\"}\n",
    "for k, v in replace.items():\n",
    "    df[\"roaster\"] = df[\"roaster\"].str.replace(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roaster\n",
    "\n",
    "Let's first verify that the information about each roaster (in this case only country) is consistent across all coffees from the same roaster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _assert_identical_values(df: pd.DataFrame) -> pd.Series:\n",
    "    assert (df.iloc[1:, :] == df.iloc[0, :]).all().all()\n",
    "    return df.iloc[0, :]\n",
    "\n",
    "\n",
    "roaster_map = df[[\"roaster\", \"roaster_country\"]].groupby(\"roaster\").apply(_assert_identical_values)[\"roaster_country\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flavour notes\n",
    "As it stands, we cannot glean any information from the review column as it is unstructured. Let's begin by analysing the keywords present in the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "COFFEE_WORDS = {\"cup\", \"notes\", \"finish\", \"aroma\", \"hint\", \"undertones\", \"mouthfeel\", \"structure\", \"toned\"}\n",
    "\n",
    "word_cloud = WordCloud(\n",
    "    collocations=False, width=2000, height=1000, background_color='white', stopwords=set(STOPWORDS) | COFFEE_WORDS\n",
    ").generate(\" \".join(df[\"review\"]))\n",
    "word_cloud.to_file('charts/word_cloud.png')\n",
    "px.imshow(word_cloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the most common words relate to the flavour of the coffee. This suggests that we can extract some features for the different flavours in the coffee.\n",
    "\n",
    "Using this information and the [coffee flavour wheel](https://www.anychart.com/products/anychart/gallery/Sunburst_Charts/Coffee_Flavour_Wheel.php), we can manually define some flavours and corresponding keywords which are stored in `flavours.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/flavours.json\", \"r\") as f:\n",
    "    FLAVOURS = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now add boolean features for each flavour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def extract_words(string: str) -> list[str]:\n",
    "    return re.findall(r'\\w+', string.lower())\n",
    "\n",
    "\n",
    "def rating_contains_words(review: str, keywords: list[str]) -> bool:\n",
    "    words = extract_words(review)\n",
    "    for w in keywords:\n",
    "        if w in words:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "for flavour, keywords in FLAVOURS.items():\n",
    "    df[flavour] = df[\"review\"].apply(rating_contains_words, args=(keywords,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now combine the flavours into a single column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"flavours\"] = df.apply(lambda coffee: [flavour for flavour in FLAVOURS if coffee[flavour]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also convenient to check how many flavours the different coffees have. If we have done a good job at defining the flavour keywords, we would expect not many coffees to have no flavours.\n",
    "\n",
    "This appears to be the case. In fact, most coffees have 6 flavours!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_flavours = df[list(FLAVOURS.keys())].sum(axis=1)\n",
    "fig = plot_hist(num_flavours.to_frame(\"num_flavours\"), \"num_flavours\", bins=[i + 0.5 for i in range(0, 12)])\n",
    "write_fig_to_html(fig, \"num_flavours_hist.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region of origin\n",
    "The different regions of the world typically produce coffees which are similar in style. Eg African coffees are typically more acidic. Therefore it seems possible that the region may provide as much information as the country of origin. We will therefore engineer this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/regions.json\", \"r\") as f:\n",
    "    REGIONS = json.load(f)\n",
    "\n",
    "regions = {}\n",
    "for r, countries in REGIONS.items():\n",
    "    for c in countries:\n",
    "        regions[c] = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"region_of_origin\"] = df[\"country_of_origin\"].map(regions).fillna(\"Other\").astype(\"string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of each feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating\n",
    "We can see that the ratings appear to be approximately normally distributed. However, there is a large offset, with the median rating is ~94% which is very high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_hist(df, \"rating\", bins=[i + 0.5 for i in range(80, 101)])\n",
    "write_fig_to_html(fig, \"rating_hist.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price\n",
    "The distributon for the price of the coffee has a very long tail. This suggests that there may be benefit in applying the log transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_hist(df, \"price_per_100g\", bins=80)\n",
    "fig.show()\n",
    "write_fig_to_html(fig, \"price_hist.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have applied the log transformation, the distribution is closer to a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"log_price_per_100g\"] = df[\"price_per_100g\"].apply(np.log1p)\n",
    "fig = plot_hist(df, \"log_price_per_100g\", bins=30)\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()\n",
    "write_fig_to_html(fig, \"price_log_hist.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roasting style\n",
    "The vast majority of the coffee have the medium-light roast type. This large uneveness in the dataset may make it challenging for a model to detect any impact of roast style on coffee rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"roast\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_hist(df, \"roast\", bins=[\"Light\", \"Medium-Light\", \"Medium\", \"Medium-Dark\", \"Dark\"])\n",
    "fig.show()\n",
    "write_fig_to_html(fig, \"roast_hist.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roaster country\n",
    "Most of the data we have is from US rosters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"roaster_country\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the distribution of pricing for the most common countries, we see that the distribution is quite different in each country. In particular, the coffees sold in the US are much more \"peaky\". This likely indicates that there is some bias in the dataset. Given that the source of the data is from the US, there are most coffees in the database at an afforable pricepoint (for US customers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "countries = [\"United States\", \"Taiwan\", \"Guatemala\"]\n",
    "fig = plot_hist(\n",
    "    df[df[\"roaster_country\"].apply(lambda c: c in countries)], \"price_per_100g\", by=\"roaster_country\", bins=80\n",
    ")\n",
    "fig.show()\n",
    "write_fig_to_html(fig, \"roaster_country_hist.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country of origin\n",
    "As expected, most of the coffees come from the largest coffee producers in the world. All examples are from one of the following regions:\n",
    "\n",
    "- Africa\n",
    "- Central or South America\n",
    "with the exception of Hawaii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_hist(df, \"country_of_origin\")\n",
    "fig.show()\n",
    "write_fig_to_html(fig, \"origin_country_hist.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region of origin\n",
    "The vast majority of coffees in the dataset come from the major coffee producing regions of the world as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_hist(df, \"region_of_origin\", bins=list(REGIONS) + [\"Other\"])\n",
    "fig.show()\n",
    "write_fig_to_html(fig, \"origin_region_hist.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flavour notes\n",
    "It is useful to examine the popularity of the different flavours, by plotting the histogram. We can see that the most common flavours are:\n",
    "- Caramelly\n",
    "- Acidic\n",
    "- Fruity\n",
    "- Chocolate\n",
    "\n",
    "Intuitively, this makes sense as these are the sorts of flavours we see on coffee packets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = (\n",
    "    df[list(FLAVOURS.keys())]\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .multiply(100)\n",
    "    .plot.bar(labels={\"index\": \"flavour\", \"value\": \"percent\"})\n",
    ")\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()\n",
    "write_fig_to_html(fig, \"flavour_hist.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influence on rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = df.plot.scatter(x=\"price_per_100g\", y=\"rating\")\n",
    "fig.show()\n",
    "write_fig_to_html(fig, \"rating_against_price.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the highest and lowest rates coffees, we see that they are dominated by certain roasters. This suggests that either:\n",
    "- Certain roaster find the best/worst coffees or roast them particulraly well\n",
    "- The reviewers favour/dislike certainer roasters\n",
    "\n",
    "In either case, our model may need to access the roaster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"rating\"] > 96, [\"name\", \"roaster\"]].groupby(\"roaster\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"rating\"] < 90, [\"name\", \"roaster\"]].groupby(\"roaster\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.groupby(\"popular_roaster\")[\"rating\"].mean()\n",
    "fig = data[popular_roasters].plot.bar(labels={\"popular_roaster\": \"roaster\", \"value\": \"rating\"})\n",
    "fig.add_hline(df[\"rating\"].mean(), line_dash=\"dash\")\n",
    "fig.update_yaxes(range=[85, 100])\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()\n",
    "write_fig_to_html(fig, \"mean_rating_by_roaster.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roasting style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_hist(df, \"rating\", by=\"roast\", bins=[i + 0.5 for i in range(80, 101)])\n",
    "write_fig_to_html(fig, \"rating_hist_by_roast.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = (\n",
    "    df.groupby(\"roast\")[\"rating\"]\n",
    "    .mean()[[\"Light\", \"Medium-Light\", \"Medium\", \"Medium-Dark\", \"Dark\"]]\n",
    "    .plot.bar(labels={\"value\": \"rating\"})\n",
    ")\n",
    "fig.add_hline(df[\"rating\"].mean(), line_dash=\"dash\")\n",
    "fig.update_yaxes(range=[90, 96])\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()\n",
    "write_fig_to_html(fig, \"mean_rating_by_roast.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_hist(df, \"rating\", by=\"region_of_origin\", bins=[i + 0.5 for i in range(80, 101)])\n",
    "write_fig_to_html(fig, \"rating_hist_by_origin.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = df.groupby(\"region_of_origin\")[\"rating\"].mean().plot.bar(labels={\"value\": \"rating\"})\n",
    "fig.add_hline(df[\"rating\"].mean(), line_dash=\"dash\")\n",
    "fig.update_yaxes(range=[90, 96])\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()\n",
    "write_fig_to_html(fig, \"mean_rating_by_origin.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flavour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_with_flavour = pd.Series({f: df.loc[df[f], \"rating\"].mean() for f in FLAVOURS})\n",
    "rating_without_flavour = pd.Series({f: df.loc[~df[f], \"rating\"].mean() for f in FLAVOURS})\n",
    "fig = (rating_with_flavour - rating_without_flavour).plot.bar(labels={\"index\": \"flavour\", \"value\": \"rating_delta\"})\n",
    "fig.add_hline(df[\"rating\"].mean(), line_dash=\"dash\")\n",
    "fig.update_yaxes(range=[-2, 2])\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()\n",
    "write_fig_to_html(fig, \"mean_rating_by_flavour.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "We can get a quick insight into which features might be important by analysing:\n",
    "- The correlation coefficient for continuous variables\n",
    "- The mutual information for categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "mutual_info = pd.Series(\n",
    "    {\n",
    "        k: mutual_info_score(df[k], df[\"rating\"])\n",
    "        for k in [\"roaster\", \"roast\", \"roaster_country\", \"country_of_origin\", \"region_of_origin\"]\n",
    "    }\n",
    ")\n",
    "mutual_info.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info_flavours = pd.Series({k: mutual_info_score(df[k], df[\"rating\"]) for k in FLAVOURS})\n",
    "mutual_info_flavours.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"price_per_100g\"]].apply(np.log1p).corrwith(df[\"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roasters = df[\"roaster\"].value_counts()\n",
    "popular_roasters = sorted(roasters[roasters > 10].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is evidence that certain roasters product particularly good/poor coffee (or are preferred/disliked by the reviewers). The model may therefore need a feature giving it this information.\n",
    "\n",
    "We cannot simply convert the roaster using one-hot encoding as there are too many different values. Let us instead only include the most common roasters (those with > 10 coffees)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save this information to file for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roaster_info = {\"known_roasters\": roaster_map.to_dict(), \"popular_roasters\": popular_roasters}\n",
    "with open(\"data/roasters.json\", \"w\") as f:\n",
    "    json.dump(roaster_info, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"popular_roaster\"] = df[\"roaster\"].where(df[\"roaster\"].apply(lambda r: r in popular_roasters), \"Other\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"popular_roaster\", \"roaster_country\", \"roast\", \"country_of_origin\", \"price_per_100g\"]].copy()\n",
    "X[\"price_per_100g\"] = X[\"price_per_100g\"].apply(np.log1p)\n",
    "X[\"flavours\"] = df.apply(\n",
    "    lambda coffee: [flavour for flavour in [\"fruity\", \"resinous\", \"spicy\", \"nutty\"] if coffee[flavour]], axis=1\n",
    ")\n",
    "y = df[\"rating\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Split the dataset into train/validation/test sets with 60%/20%/20% distribution. \n",
    "* Use the `train_test_split` function and set the `random_state` parameter to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_val, X_test = train_test_split(X, test_size=0.2, random_state=1)\n",
    "y_train_val, y_test = train_test_split(y, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val = train_test_split(X_train_val, test_size=0.25, random_state=1)\n",
    "y_train, y_val = train_test_split(y_train_val, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "dv.fit(X_train.to_dict(orient=\"records\"))\n",
    "\n",
    "\n",
    "def _transform(df: pd.DataFrame):\n",
    "    return dv.transform(df.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "Let's start with the simplest model which is a linear regressor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "scores_linear = pd.DataFrame(columns=[\"train\", \"validation\"])\n",
    "for alpha in [0.01, 0.03, 0.1, 0.3, 1.0, 3.0, 10.0, 100.0]:\n",
    "    model = Ridge(alpha=alpha)\n",
    "    model.fit(_transform(X_train), y_train)\n",
    "    scores_linear.loc[alpha, :] = pd.Series(\n",
    "        {\n",
    "            \"train\": mean_squared_error(y_train, model.predict(_transform(X_train)), squared=False),\n",
    "            \"validation\": mean_squared_error(y_val, model.predict(_transform(X_val)), squared=False),\n",
    "        }\n",
    "    )\n",
    "\n",
    "fig = scores_linear.plot(log_x=True, labels={\"index\": \"alpha\", \"value\": \"rmse\"})\n",
    "fig.show()\n",
    "write_fig_to_html(fig, \"linear_losses.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests that the best value is 1.0 since this gives the same loss on the validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = Ridge(alpha=1.0)\n",
    "linear_model.fit(_transform(X_train_val), y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = px.scatter(x=linear_model.predict(_transform(X_val)), y=y_val)\n",
    "fig.add_trace(go.Scatter(x=[80, 100], y=[80, 100], showlegend=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model captures the central part of the distribution quite well, but fails to predict the very high or low ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_hist(models: dict[str, Ridge], X: pd.DataFrame, y: pd.Series) -> go.Figure:\n",
    "    data = pd.concat(\n",
    "        [pd.DataFrame({\"rating\": y, \"type\": \"truth\"})]\n",
    "        + [\n",
    "            pd.DataFrame({\"rating\": np.round(model.predict(_transform(X)), decimals=0), \"type\": name})\n",
    "            for name, model in models.items()\n",
    "        ]\n",
    "    )\n",
    "    return plot_hist(data, \"rating\", by=\"type\", bins=80)\n",
    "\n",
    "\n",
    "plot_model_hist({\"ridge\": linear_model}, X_train_val, y_train_val)\n",
    "fig.show()\n",
    "write_fig_to_html(fig, \"linear_hist.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get a bit more insight by evaluating the importance of the difference features.\n",
    "\n",
    "The price is the biggest influence by far which suggests that either:\n",
    "- Price is genuinely an indicator of quality\n",
    "- Price biases the reviewers\n",
    "\n",
    "Other than the price, the region of origin plays a big influence. Surprisingly only certain flavour notes have much influence; \"resinous\" and \"fruity\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "r = permutation_importance(linear_model, _transform(X_train_val), y_train_val, n_repeats=10, random_state=0)\n",
    "linear_importances = pd.Series(dict(zip(dv.get_feature_names_out(), r.importances_mean)))\n",
    "linear_importances[linear_importances.abs().sort_values(ascending=False).index].iloc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient-boosted trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "eval_sets = {\n",
    "    \"train\": (_transform(X_train), y_train),\n",
    "    \"validation\": (_transform(X_val), y_val),\n",
    "}\n",
    "\n",
    "scores_max_depth = {}\n",
    "for max_depth in [1, 2, 3, 4, 5]:\n",
    "    xgb_params = {\n",
    "        'max_depth': max_depth,\n",
    "        'min_child_weight': 1,\n",
    "        'objective': 'reg:squarederror',\n",
    "        'seed': 1,\n",
    "        'verbosity': 1,\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBRegressor(**xgb_params, eval_metric=\"rmse\")\n",
    "    model.fit(_transform(X_train), y_train, eval_set=list(eval_sets.values()))\n",
    "\n",
    "    results = model.evals_result()\n",
    "    scores_max_depth[max_depth] = pd.DataFrame({k: results[f\"validation_{i}\"][\"rmse\"] for i, k in enumerate(eval_sets)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = px.colors.qualitative.Plotly\n",
    "fig = go.Figure()\n",
    "for i, (depth, scores) in enumerate(scores_max_depth.items()):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=scores.index, y=scores[\"train\"], name=f\"{depth} (train)\", line_dash=\"dash\", line_color=COLORS[i])\n",
    "    )\n",
    "    fig.add_trace(go.Scatter(x=scores.index, y=scores[\"validation\"], name=f\"{depth} (val)\", line_color=COLORS[i]))\n",
    "\n",
    "fig.update_layout(xaxis_title=\"n_estimators\", yaxis_title=\"rmse\", legend_title_text=\"max_depth\")\n",
    "fig.show()\n",
    "write_fig_to_html(fig, \"trees_losses_depth.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us select max depth 2 with 20 estimators, since this gives the lowest validation loss without overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_eta = {}\n",
    "for eta in [0.01, 0.03, 0.1, 0.3, 1.0]:\n",
    "    xgb_params = {\n",
    "        'max_depth': 2,\n",
    "        'n_estimators': 20,\n",
    "        \"eta\": eta,\n",
    "        'min_child_weight': 1,\n",
    "        'objective': 'reg:squarederror',\n",
    "        'seed': 1,\n",
    "        'verbosity': 1,\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBRegressor(**xgb_params, eval_metric=\"rmse\")\n",
    "    model.fit(_transform(X_train), y_train, eval_set=list(eval_sets.values()))\n",
    "\n",
    "    results = model.evals_result()\n",
    "    scores_eta[eta] = pd.DataFrame({k: results[f\"validation_{i}\"][\"rmse\"] for i, k in enumerate(eval_sets)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for i, (eta, scores) in enumerate(scores_eta.items()):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=scores.index, y=scores[\"train\"], name=f\"{eta} (train)\", line_dash=\"dash\", line_color=COLORS[i])\n",
    "    )\n",
    "    fig.add_trace(go.Scatter(x=scores.index, y=scores[\"validation\"], name=f\"{eta} (val)\", line_color=COLORS[i]))\n",
    "\n",
    "fig.update_layout(xaxis_title=\"n_estimators\", yaxis_title=\"rmse\", legend_title_text=\"eta\")\n",
    "fig.show()\n",
    "write_fig_to_html(fig, \"trees_losses_eta.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select `eta` = 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'max_depth': 2,\n",
    "    'n_estimators': 20,\n",
    "    \"eta\": 0.3,\n",
    "    'min_child_weight': 1,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "xgb_model = xgb.XGBRegressor(**xgb_params, eval_metric=\"rmse\")\n",
    "xgb_model.fit(_transform(X_train_val), y_train_val, eval_set=[(_transform(X_train_val), y_train_val)])\n",
    "results = xgb_model.evals_result()\n",
    "scores_xgb = pd.Series(results[f\"validation_0\"][\"rmse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_xgb.plot(labels={\"index\": \"n_estimators\", \"value\": \"rmse\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way as the linear model, this model fails to capture the very low or high ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_hist({\"xgb\": xgb_model}, X_train_val, y_train_val)\n",
    "write_fig_to_html(fig, \"trees_hist.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the biggest influencer is the price as we found with the linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = permutation_importance(xgb_model, _transform(X_train_val), y_train_val, n_repeats=10, random_state=0)\n",
    "xgb_importances = pd.Series(dict(zip(dv.get_feature_names_out(), r.importances_mean)))\n",
    "xgb_importances[xgb_importances.abs().sort_values(ascending=False).index].iloc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of the models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"linear\": linear_model, \"xgb\": xgb_model}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both models perform similarly well on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_comparison = pd.DataFrame(dtype=float)\n",
    "for name, model in models.items():\n",
    "    loss_train = mean_squared_error(y_train_val, model.predict(_transform(X_train_val)), squared=False)\n",
    "    loss_test = mean_squared_error(y_test, model.predict(_transform(X_test)), squared=False)\n",
    "    scores_comparison[name] = pd.Series({\"train\": loss_train, \"test\": loss_test})\n",
    "\n",
    "fig = px.bar(scores_comparison.transpose(), barmode=\"group\", labels={\"index\": \"model\", \"value\": \"rmse\"})\n",
    "fig.show()\n",
    "write_fig_to_html(fig, \"comparison_losses.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also see that they lead to the same distribution of ratings. This suggests that the model is not the reason for failing to predict the highest/lowest scores is more due to some other more systematic error such as:\n",
    "- Lack of information in the features (eg perhaps we need more detailed information about the origin)\n",
    "- System error in the reviews (eg different reviewers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_model_hist(models, X_test, y_test)\n",
    "fig.show()\n",
    "write_fig_to_html(fig, \"comparison_hist.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model selection\n",
    "Overall, the two models have very similar performance. Since the linear regression model is simpler (and has slightly better performance), this is the preferred model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
