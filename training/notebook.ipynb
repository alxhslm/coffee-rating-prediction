{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coffee price prediction\n",
    "The objective is to predict the rating of coffee beans based on their origin, flavour and tasting notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/simplified_coffee.csv\")\n",
    "for col in [\"name\", \"roaster\", \"roast\", \"loc_country\", \"origin\", \"review\"]:\n",
    "    df[col] = df[col].astype(\"string\")\n",
    "\n",
    "df[\"review_date\"] = pd.to_datetime(df[\"review_date\"])\n",
    "df = df.rename(columns={\"loc_country\": \"roaster_country\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first check for NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only column with NaNs is the roast. Since there are only 12 missing values, we could just remove these rows. However, since most coffees have the same roast type (as will see later), let us fill with the modal value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"roast\"] = df[\"roast\"].fillna(df[\"roast\"].mode().iloc[0])\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fix a typo in the roaster country for one coffee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"roaster_country\"] = df[\"roaster_country\"].str.replace(\"New Taiwan\", \"Taiwan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ratings\n",
    "We can see that the ratings are approximately normally distribution. However, there is a large offset, with the median rating is ~94% which is very high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"rating\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coffee pricing\n",
    "The distributon for the price of the coffee has a very long tail. This suggests that there may be benefit in applying the log transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"100g_USD\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have applied the log transformation, the distribution is closer to a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"100g_USD\"].apply(np.log1p).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roasting style\n",
    "The vast majority of the coffee have the medium-light roast type. This large uneveness in the dataset may make it challenging for a model to detect any impact of roast style on coffee rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"roast\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roaster country\n",
    "Most of the data we have is from US rosters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"roaster_country\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the distribution of pricing for the most common countries, we see that the distribution is quite different in each country. In particular, the coffees sold in the US are much more \"peaky\". This likely indicates that there is some bias in the dataset. Given that the source of the data is from the US, there are most coffees in the database at an afforable pricepoint (for US customers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "countries = [\"United States\", \"Taiwan\", \"Guatemala\"]\n",
    "px.histogram(\n",
    "    df[df[\"roaster_country\"].apply(lambda c: c in countries)],\n",
    "    x=\"100g_USD\",\n",
    "    color=\"roaster_country\",\n",
    "    barmode=\"group\",\n",
    "    histnorm='percent',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country of origin\n",
    "As expected, most of the coffees come from the largest coffee producers in the world. All examples are from one of the following regions:\n",
    "\n",
    "- Africa\n",
    "- Central or South America\n",
    "with the exception of Hawaii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"origin\"].hist(histnorm='percent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highly and lowly rated coffees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the highest and lowest rates coffees, we see that they are dominated by certain roasters. This suggests that either:\n",
    "- Certain roaster find the best/worst coffees or roast them particulraly well\n",
    "- The reviewers favour/dislike certainer roasters\n",
    "\n",
    "In either case, our model may need to access the roaster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"rating\"] > 96]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"rating\"] < 90]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roaster\n",
    "There is evidence that certain roasters product particularly good/poor coffee (or are preferred/disliked by the reviewers). The model may therefore need a feature giving it this information.\n",
    "\n",
    "We cannot simply convert the roaster using one-hot encoding as there are too many different values. Let us instead only include the most common roasters (those with > 10 coffees)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roasters = df[\"roaster\"].value_counts()\n",
    "ROASTERS = roasters[roasters > 10].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"roaster\"] = df[\"roaster\"].where(df[\"roaster\"].apply(lambda r: r in ROASTERS), \"Other\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region of origin\n",
    "The different regions of the world typically produce coffees which are similar in style. Eg African coffees are typically more acidic. Therefore it seems possible that the region may provide as much information as the country of origin. We will therefore engineer this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./data/regions.json\", \"r\") as f:\n",
    "    REGIONS = json.load(f)\n",
    "\n",
    "regions = {}\n",
    "for r, countries in REGIONS.items():\n",
    "    for c in countries:\n",
    "        regions[c] = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"region\"] = df[\"origin\"].map(regions).fillna(\"Other\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vast majority of coffees in the dataset come from the major coffee producing regions of the world as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"region\"].hist(histnorm=\"percent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flavour notes\n",
    "As it stands, we cannot glean any information from the review column as it is unstructured. Let's begin by analysing the keywords present in the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def extract_words(string: str) -> list[str]:\n",
    "    return re.findall(r'\\w+', string.lower())\n",
    "\n",
    "\n",
    "words = pd.Series([word for review in df[\"review\"] for word in extract_words(review)]).value_counts()\n",
    "\n",
    "GENERIC_WORDS = [\"and\", \"in\", \"with\", \"the\", \"of\", \"to\", \"a\", \"by\", \"like\", \"is\", \"around\"]\n",
    "COFFEE_WORDS = [\"cup\", \"notes\", \"finish\", \"aroma\", \"hint\", \"undertones\", \"resonant\", \"high\", \"consolidates\", \"flavor\"]\n",
    "words = words.drop(GENERIC_WORDS + COFFEE_WORDS)\n",
    "words.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the most common words relate to the flavour of the coffee. This suggests that we can extract some features for the different flavours in the coffee.\n",
    "\n",
    "Using this information and the [coffee flavour wheel](https://www.anychart.com/products/anychart/gallery/Sunburst_Charts/Coffee_Flavour_Wheel.php), we can manually define some flavours and corresponding keywords which are stored in `flavours.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./data/flavours.json\", \"r\") as f:\n",
    "    FLAVOURS = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now add boolean features for each flavour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_contains_words(review: str, keywords: list[str]) -> bool:\n",
    "    words = extract_words(review)\n",
    "    for w in keywords:\n",
    "        if w in words:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "for flavour, keywords in FLAVOURS.items():\n",
    "    df[flavour] = df[\"review\"].apply(rating_contains_words, args=(keywords,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity of flavours\n",
    "It is useful to examine the popularity of the different flavours, by plotting the histogram. We can see that the most common flavours are:\n",
    "- Caramelly\n",
    "- Acidic\n",
    "- Fruity\n",
    "- Chocolate\n",
    "\n",
    "Intuitively, this makes sense as these are the sorts of flavours we see on coffee packets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[list(FLAVOURS.keys())].sum().divide(df.shape[0]).sort_values(ascending=False).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of flavours per coffee\n",
    "It is also convenient to check how many flavours the different coffees have. If we have done a good job at defining the flavour keywords, we would expect not many coffees to have no flavours.\n",
    "\n",
    "This appears to be the case. In fact, most coffees have 6 flavours!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_flavours = df[list(FLAVOURS.keys())].sum(axis=1)\n",
    "num_flavours.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"roaster\", \"roast\", \"roaster_country\", \"region\", \"100g_USD\"] + list(FLAVOURS.keys())\n",
    "X = df[features].copy()\n",
    "X[\"100g_USD\"] = X[\"100g_USD\"].apply(np.log1p)\n",
    "y = df[\"rating\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Split the dataset into train/validation/test sets with 60%/20%/20% distribution. \n",
    "* Use the `train_test_split` function and set the `random_state` parameter to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_val, X_test = train_test_split(X, test_size=0.2, random_state=1)\n",
    "y_train_val, y_test = train_test_split(y, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val = train_test_split(X_train_val, test_size=0.25, random_state=1)\n",
    "y_train, y_val = train_test_split(y_train_val, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "dv.fit(X_train.to_dict(orient=\"records\"))\n",
    "\n",
    "\n",
    "def _transform(df: pd.DataFrame):\n",
    "    return dv.transform(df.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "Let's start with the simplest model which is a linear regressor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "scores = pd.DataFrame(columns=[\"test\", \"validation\"])\n",
    "for alpha in [0.01, 0.03, 0.1, 0.3, 1.0, 3.0, 10.0]:\n",
    "    model = Ridge(alpha=alpha)\n",
    "    model.fit(_transform(X_train), y_train)\n",
    "    scores.loc[alpha, :] = pd.Series(\n",
    "        {\n",
    "            \"test\": mean_squared_error(y_train, model.predict(_transform(X_train)), squared=False),\n",
    "            \"validation\": mean_squared_error(y_val, model.predict(_transform(X_val)), squared=False),\n",
    "        }\n",
    "    )\n",
    "\n",
    "scores.plot(log_x=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests that the best value is 1.0 since this gives the same loss on the validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = Ridge(alpha=1.0)\n",
    "linear_model.fit(_transform(X_train_val), y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = px.scatter(x=linear_model.predict(_transform(X_val)), y=y_val)\n",
    "fig.add_trace(go.Scatter(x=[80, 100], y=[80, 100], showlegend=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model captures the central part of the distribution quite well, but fails to predict the very high or low ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {\"true\": y_train_val, \"prediction\": np.round(linear_model.predict(_transform(X_train_val)), decimals=0)}\n",
    ").hist(histnorm=\"percent\", barmode=\"group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient-boosted trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "eval_sets = {\n",
    "    \"train\": (_transform(X_train), y_train),\n",
    "    \"validation\": (_transform(X_val), y_val),\n",
    "}\n",
    "\n",
    "scores = {}\n",
    "for max_depth in [1, 2, 3, 4, 5]:\n",
    "    xgb_params = {\n",
    "        'max_depth': max_depth,\n",
    "        'min_child_weight': 1,\n",
    "        'objective': 'reg:squarederror',\n",
    "        'seed': 1,\n",
    "        'verbosity': 1,\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBRegressor(**xgb_params, eval_metric=\"rmse\")\n",
    "    model.fit(_transform(X_train), y_train, eval_set=list(eval_sets.values()))\n",
    "\n",
    "    results = model.evals_result()\n",
    "    scores[max_depth] = pd.DataFrame({k: results[f\"validation_{i}\"][\"rmse\"] for i, k in enumerate(eval_sets)})\n",
    "\n",
    "pd.DataFrame({depth: df[\"validation\"] for depth, df in scores.items()}).plot(\n",
    "    labels={\"index\": \"n_estimators\", \"variable\": \"max_depth\", \"value\": \"rmse\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us select max depth 3 with 90 estimators, since this gives the lowest validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for eta in [0.01, 0.03, 0.1, 0.3, 1.0]:\n",
    "    xgb_params = {\n",
    "        'max_depth': 3,\n",
    "        'n_estimators': 90,\n",
    "        \"eta\": eta,\n",
    "        'min_child_weight': 1,\n",
    "        'objective': 'reg:squarederror',\n",
    "        'seed': 1,\n",
    "        'verbosity': 1,\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBRegressor(**xgb_params, eval_metric=\"rmse\")\n",
    "    model.fit(_transform(X_train), y_train, eval_set=list(eval_sets.values()))\n",
    "\n",
    "    results = model.evals_result()\n",
    "    scores[eta] = pd.DataFrame({k: results[f\"validation_{i}\"][\"rmse\"] for i, k in enumerate(eval_sets)})\n",
    "\n",
    "pd.DataFrame({eta: df[\"validation\"] for eta, df in scores.items()}).plot(\n",
    "    labels={\"index\": \"n_estimators\", \"variable\": \"eta\", \"value\": \"rmse\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select `eta` = 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'max_depth': 3,\n",
    "    'n_estimators': 90,\n",
    "    \"eta\": 0.3,\n",
    "    'min_child_weight': 1,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "xgb_model = xgb.XGBRegressor(**xgb_params, eval_metric=\"rmse\")\n",
    "xgb_model.fit(_transform(X_train_val), y_train_val, eval_set=[(_transform(X_train_val), y_train_val)])\n",
    "results = xgb_model.evals_result()\n",
    "scores = pd.Series(results[f\"validation_0\"][\"rmse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.plot(labels={\"index\": \"n_estimators\", \"value\": \"rmse\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way as the linear model, this model fails to capture the very low or high ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"true\": y_train_val,\n",
    "        \"prediction\": np.round(xgb_model.predict(_transform(X_train_val)), decimals=0),\n",
    "    }\n",
    ").hist(histnorm=\"percent\", barmode=\"group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of the models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"linear\": linear_model, \"xgb\": xgb_model}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both models perform similarly well on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.Series(dtype=float)\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(_transform(X_test))\n",
    "    scores[name] = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "scores.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also see that they lead to the same distribution of ratings. This suggests that the model is not the reason for failing to predict the highest/lowest scores is more due to some other more systematic error such as:\n",
    "- Lack of information in the features (eg perhaps we need more detailed information about the origin)\n",
    "- System error in the reviews (eg different reviewers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {\"true\": y_test} | {name: np.round(model.predict(_transform(X_test)), decimals=0) for name, model in models.items()}\n",
    ").hist(histnorm=\"percent\", barmode=\"group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importances\n",
    "We can get a bit more insight by evaluating the importance of the difference features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "importances = {}\n",
    "for name, model in models.items():\n",
    "    r = permutation_importance(model, _transform(X_test), y_test, n_repeats=10, random_state=0)\n",
    "    importances[name] = pd.Series(dict(zip(dv.get_feature_names_out(), r.importances_mean)))\n",
    "\n",
    "importances = pd.DataFrame(importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see in both cases that the biggest influence is the price. This suggests that either:\n",
    "- Price is genuinely an indicator of quality\n",
    "- Price biases the reviewers\n",
    "\n",
    "Other than the price, the region of origin plays a big influence. Surprisingly the flavour notes do not have that much influence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances.loc[importances.max(axis=1).sort_values(ascending=False).index].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model selection\n",
    "Overall, the two models have very similar performance. Since the linear regression model is simpler (and has slightly better performance), this is the preferred model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
